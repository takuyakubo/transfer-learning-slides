<!-- 転移学習問題の分類 スライド2（続き） -->
<div class="slide">
    <h2>5. 転移学習問題の分類（続き）</h2>
    
    <h3>ドメイン適応（Domain Adaptation）</h3>
    <ul>
        <li>最も基本的な転移学習の問題設定</li>
        <li>元ドメインから目標ドメインへの<span class="highlight">直接的な知識転移</span></li>
        <li>各ドメインとその役割は固定</li>
        <li><span class="key-point">例:</span> スマートフォンのカメラで撮影した画像（元ドメイン）から医療用カメラの画像（目標ドメイン）への適応</li>
    </ul>
    
    <h3>マルチタスク学習（Multitask Learning）</h3>
    <ul>
        <li>複数の関連タスクを<span class="highlight">同時に学習</span></li>
        <li>タスク間の共通知識を活用</li>
        <li>各タスクの性能向上が目標</li>
        <li><span class="key-point">例:</span> 複数の言語の翻訳を同時に学習し、言語間の共通構造を活用</li>
    </ul>
</div>

<!-- 転移学習問題の分類 スライド3 -->
<div class="slide">
    <h2>5. 転移学習問題の分類（続き）</h2>
    
    <h3>メタ学習（Meta Learning）</h3>
    <ul>
        <li>「<span class="highlight">学習の仕方を学習する</span>」アプローチ</li>
        <li>複数のタスクが共通の確率分布から生成されていると仮定</li>
        <li>少量のデータでの効率的な学習が目標</li>
        <li>関連するアプローチ：<span class="key-point">少数ショット学習</span>（Few-shot Learning）、<span class="key-point">ドメイン汎化</span>（Domain Generalization）</li>
        <li><span class="key-point">例:</span> 新しい言語を数例のサンプルだけで効率的に学習する</li>
    </ul>
    
    <h3>継続学習（Continual Learning）</h3>
    <ul>
        <li><span class="highlight">逐次的に与えられるタスク</span>での繰り返し学習</li>
        <li>過去の知識を忘れずに新しいタスクを学習</li>
        <li>タスク系列全体の性能で評価</li>
        <li><span class="key-point">例:</span> ロボットが環境変化に順応しながら徐々に新しいスキルを獲得</li>
    </ul>
</div>

<!-- 深層学習時代の転移学習 スライド1 -->
<div class="slide">
    <h2>6. 深層学習時代の転移学習</h2>
    
    <h3>深層学習が転移学習にもたらした3つの変革</h3>
    <ol>
        <li><span class="highlight">深層モデル自体の大きな容量</span>（capacity）</li>
        <li><span class="highlight">表現学習の性能向上</span></li>
        <li><span class="highlight">事前学習済みモデルの利用容易化</span></li>
    </ol>
    
    <div class="note">
        深層学習の普及により、転移学習の研究方向性は大きく変わりました。特に事前学習済みモデルを活用した転移学習は、現在の機械学習応用の主流となっています。
    </div>
</div>

<!-- 深層学習時代の転移学習 スライド2 -->
<div class="slide">
    <h2>6. 深層学習時代の転移学習（続き）</h2>
    
    <h3>1. 深層モデルの大きな容量</h3>
    <ul>
        <li>「容量」：モデルが表現できる<span class="highlight">関数の複雑さ</span></li>
        <li>深層ニューラルネットワークは大規模データを「丸暗記」できるほどの容量</li>
        <li>複数タスクを単一モデルで処理可能に</li>
        <li>マルチタスク学習やメタ学習に特に有効</li>
    </ul>
    
    <h3>2. 表現学習の性能向上</h3>
    <ul>
        <li>深層ニューラルネットワークによる<span class="highlight">豊かな特徴表現</span>の獲得</li>
        <li>「ドメイン不変な表現」の効果的な学習</li>
        <li>異なるドメイン間の共通特徴を自動的に抽出</li>
        <li>ドメイン適応問題において特に効果的</li>
    </ul>
</div>

<!-- 深層学習時代の転移学習 スライド3 -->
<div class="slide">
    <h2>6. 深層学習時代の転移学習（続き）</h2>
    
    <h3>3. 事前学習済みモデルの利用</h3>
    <div class="two-col">
        <div class="col">
            <h4>従来の機械学習</h4>
            <ul>
                <li>特徴抽出器と予測器が明確に分離</li>
                <li>特徴抽出はハンドクラフト（手作業）</li>
                <li>予測器のみを学習対象とすることが多い</li>
                <li>モデル全体の最適化が困難</li>
            </ul>
        </div>
        <div class="col">
            <h4>深層学習</h4>
            <ul>
                <li>層という形で構成された統一モデル</li>
                <li>エンドツーエンドの学習</li>
                <li>特定の層を切り離して再利用可能</li>
                <li>誤差逆伝播法と確率的勾配降下法による共通学習法</li>
            </ul>
        </div>
    </div>
    
    <div class="note">
        <p><span class="key-point">重要ポイント:</span> 事前学習済みモデルの再利用により、少ないデータと計算資源で新たなタスクにモデルを適応させることが可能になりました。これは特に大規模言語モデル（LLM）や画像認識モデルなど、訓練に膨大なリソースが必要なモデルで重要です。</p>
    </div>
</div>

<!-- ディスカッションスライド -->
<div class="slide">
    <h2>7. ディスカッションと演習</h2>
    
    <h3>考察テーマ</h3>
    <ul>
        <li>現在の機械学習プロジェクトでは、どのような転移学習的アプローチが使われているか？</li>
        <li>転移学習を効果的に活用するためには、どのような条件が必要か？</li>
        <li>転移学習の失敗例（負の転移）はどのような状況で発生するか？</li>
    </ul>
    
    <h3>演習</h3>
    <ol>
        <li>医療画像診断を例に、転移学習のアプローチを考えてみよう</li>
        <li>自然言語処理における事前学習モデルの活用方法を議論しよう</li>
        <li>自分の研究分野や業務で転移学習を適用できる可能性を考えてみよう</li>
    </ol>
    
    <div class="note">
        転移学習は理論だけでなく実践的な応用が重要です。自分の専門分野でどのように活用できるか考えてみましょう。
    </div>
</div>

<!-- まとめスライド -->
<div class="slide">
    <h2>まとめ：転移学習</h2>
    
    <h3>主要概念</h3>
    <ul>
        <li>過去の学習経験を新たなタスクに転用する機械学習のパラダイム</li>
        <li>様々な問題設定：ドメイン適応、マルチタスク学習、メタ学習、継続学習</li>
        <li>深層学習と組み合わせることで高い効果を発揮</li>
    </ul>
    
    <h3>転移学習のメリット</h3>
    <ul>
        <li>少ないデータでも高性能なモデルを構築可能</li>
        <li>学習の効率化と計算資源の節約</li>
        <li>人間の学習プロセスに近い自然な学習法</li>
    </ul>
    
    <div class="note">
        次回の講義では、ドメイン適応とマルチタスク学習について詳しく学びます。第2章「ドメイン適応」、第3章「マルチタスク学習」の予習をお願いします。
    </div>
</div>